{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1c51e7ad-cc5f-4a7a-a60e-a02660466545",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c51e7ad-cc5f-4a7a-a60e-a02660466545",
        "outputId": "6a27fa16-a7fd-41d6-94d0-8c8bfc3433fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install keras\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f9ab394b-185b-43ea-ace3-e65c16037c73",
      "metadata": {
        "id": "f9ab394b-185b-43ea-ace3-e65c16037c73"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot\n",
        "from sklearn.datasets import make_moons\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.regularizers import l1_l2\n",
        "X,Y=make_moons(n_samples=100,noise=0.2,random_state=1)\n",
        "n_train=30\n",
        "trainX,testX=X[:n_train,:],X[n_train:]\n",
        "trainY,testY=Y[:n_train],Y[n_train:]\n",
        "#print(trainX)\n",
        "#print(trainY)\n",
        "#print(testX)\n",
        "#print(testY)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(500,input_dim=2,activation='relu',kernel_regularizer=l1_l2(l1=0.001,l2=0.001)))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "history=model.fit(trainX,trainY,validation_data=(testX,testY),epochs=400)\n",
        "pyplot.plot(history.history['accuracy'],label='train')\n",
        "pyplot.plot(history.history['val_accuracy'],label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S8J7aMsWeTZP",
        "outputId": "d0ba2a53-7fed-48e2-c902-95856165f1e6"
      },
      "id": "S8J7aMsWeTZP",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.7521 - accuracy: 0.6333 - val_loss: 0.7349 - val_accuracy: 0.8143\n",
            "Epoch 2/400\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.7355 - accuracy: 0.8000 - val_loss: 0.7244 - val_accuracy: 0.8000\n",
            "Epoch 3/400\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.7195 - accuracy: 0.8667 - val_loss: 0.7143 - val_accuracy: 0.8000\n",
            "Epoch 4/400\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.7038 - accuracy: 0.8667 - val_loss: 0.7045 - val_accuracy: 0.7429\n",
            "Epoch 5/400\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.6886 - accuracy: 0.9000 - val_loss: 0.6951 - val_accuracy: 0.7286\n",
            "Epoch 6/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.6738 - accuracy: 0.9000 - val_loss: 0.6860 - val_accuracy: 0.7286\n",
            "Epoch 7/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6594 - accuracy: 0.9333 - val_loss: 0.6773 - val_accuracy: 0.7286\n",
            "Epoch 8/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6455 - accuracy: 0.9333 - val_loss: 0.6690 - val_accuracy: 0.7286\n",
            "Epoch 9/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.6319 - accuracy: 0.9333 - val_loss: 0.6609 - val_accuracy: 0.7286\n",
            "Epoch 10/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6187 - accuracy: 0.9000 - val_loss: 0.6532 - val_accuracy: 0.7286\n",
            "Epoch 11/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.6059 - accuracy: 0.9000 - val_loss: 0.6458 - val_accuracy: 0.7286\n",
            "Epoch 12/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5934 - accuracy: 0.9000 - val_loss: 0.6387 - val_accuracy: 0.7286\n",
            "Epoch 13/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.5814 - accuracy: 0.9000 - val_loss: 0.6319 - val_accuracy: 0.7286\n",
            "Epoch 14/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5697 - accuracy: 0.9000 - val_loss: 0.6254 - val_accuracy: 0.7286\n",
            "Epoch 15/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.5583 - accuracy: 0.9000 - val_loss: 0.6192 - val_accuracy: 0.7286\n",
            "Epoch 16/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5473 - accuracy: 0.9000 - val_loss: 0.6132 - val_accuracy: 0.7286\n",
            "Epoch 17/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5366 - accuracy: 0.9000 - val_loss: 0.6075 - val_accuracy: 0.7286\n",
            "Epoch 18/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5263 - accuracy: 0.9000 - val_loss: 0.6021 - val_accuracy: 0.7286\n",
            "Epoch 19/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5162 - accuracy: 0.9000 - val_loss: 0.5969 - val_accuracy: 0.7286\n",
            "Epoch 20/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5065 - accuracy: 0.9000 - val_loss: 0.5920 - val_accuracy: 0.7286\n",
            "Epoch 21/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4971 - accuracy: 0.9000 - val_loss: 0.5873 - val_accuracy: 0.7286\n",
            "Epoch 22/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4881 - accuracy: 0.9000 - val_loss: 0.5829 - val_accuracy: 0.7286\n",
            "Epoch 23/400\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4793 - accuracy: 0.9000 - val_loss: 0.5787 - val_accuracy: 0.7286\n",
            "Epoch 24/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.4707 - accuracy: 0.9000 - val_loss: 0.5747 - val_accuracy: 0.7286\n",
            "Epoch 25/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.4625 - accuracy: 0.9000 - val_loss: 0.5709 - val_accuracy: 0.7286\n",
            "Epoch 26/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.4545 - accuracy: 0.9000 - val_loss: 0.5673 - val_accuracy: 0.7286\n",
            "Epoch 27/400\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4468 - accuracy: 0.9000 - val_loss: 0.5639 - val_accuracy: 0.7286\n",
            "Epoch 28/400\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4394 - accuracy: 0.9000 - val_loss: 0.5607 - val_accuracy: 0.7286\n",
            "Epoch 29/400\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4322 - accuracy: 0.9000 - val_loss: 0.5577 - val_accuracy: 0.7286\n",
            "Epoch 30/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.4253 - accuracy: 0.9000 - val_loss: 0.5548 - val_accuracy: 0.7286\n",
            "Epoch 31/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4185 - accuracy: 0.9000 - val_loss: 0.5521 - val_accuracy: 0.7286\n",
            "Epoch 32/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4121 - accuracy: 0.9000 - val_loss: 0.5495 - val_accuracy: 0.7286\n",
            "Epoch 33/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.4058 - accuracy: 0.9000 - val_loss: 0.5471 - val_accuracy: 0.7286\n",
            "Epoch 34/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3998 - accuracy: 0.9000 - val_loss: 0.5448 - val_accuracy: 0.7286\n",
            "Epoch 35/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.3941 - accuracy: 0.9000 - val_loss: 0.5426 - val_accuracy: 0.7286\n",
            "Epoch 36/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3885 - accuracy: 0.9000 - val_loss: 0.5405 - val_accuracy: 0.7286\n",
            "Epoch 37/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3832 - accuracy: 0.9000 - val_loss: 0.5386 - val_accuracy: 0.7286\n",
            "Epoch 38/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.3780 - accuracy: 0.9000 - val_loss: 0.5367 - val_accuracy: 0.7286\n",
            "Epoch 39/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3731 - accuracy: 0.9000 - val_loss: 0.5350 - val_accuracy: 0.7286\n",
            "Epoch 40/400\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.3683 - accuracy: 0.9000 - val_loss: 0.5333 - val_accuracy: 0.7286\n",
            "Epoch 41/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.3638 - accuracy: 0.9000 - val_loss: 0.5317 - val_accuracy: 0.7286\n",
            "Epoch 42/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3594 - accuracy: 0.9333 - val_loss: 0.5302 - val_accuracy: 0.7286\n",
            "Epoch 43/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3552 - accuracy: 0.9333 - val_loss: 0.5287 - val_accuracy: 0.7286\n",
            "Epoch 44/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.3512 - accuracy: 0.9333 - val_loss: 0.5273 - val_accuracy: 0.7286\n",
            "Epoch 45/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.3473 - accuracy: 0.9333 - val_loss: 0.5260 - val_accuracy: 0.7286\n",
            "Epoch 46/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.3436 - accuracy: 0.9333 - val_loss: 0.5247 - val_accuracy: 0.7286\n",
            "Epoch 47/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3400 - accuracy: 0.9333 - val_loss: 0.5234 - val_accuracy: 0.7286\n",
            "Epoch 48/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.3366 - accuracy: 0.9333 - val_loss: 0.5222 - val_accuracy: 0.7286\n",
            "Epoch 49/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.3333 - accuracy: 0.9333 - val_loss: 0.5210 - val_accuracy: 0.7286\n",
            "Epoch 50/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.3302 - accuracy: 0.9333 - val_loss: 0.5198 - val_accuracy: 0.7286\n",
            "Epoch 51/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.3271 - accuracy: 0.9000 - val_loss: 0.5186 - val_accuracy: 0.7286\n",
            "Epoch 52/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.3242 - accuracy: 0.9000 - val_loss: 0.5175 - val_accuracy: 0.7286\n",
            "Epoch 53/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.3214 - accuracy: 0.9000 - val_loss: 0.5163 - val_accuracy: 0.7286\n",
            "Epoch 54/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3187 - accuracy: 0.9000 - val_loss: 0.5152 - val_accuracy: 0.7286\n",
            "Epoch 55/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.3161 - accuracy: 0.9000 - val_loss: 0.5141 - val_accuracy: 0.7286\n",
            "Epoch 56/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3136 - accuracy: 0.9000 - val_loss: 0.5130 - val_accuracy: 0.7286\n",
            "Epoch 57/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3112 - accuracy: 0.9000 - val_loss: 0.5119 - val_accuracy: 0.7286\n",
            "Epoch 58/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3089 - accuracy: 0.9000 - val_loss: 0.5108 - val_accuracy: 0.7429\n",
            "Epoch 59/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3066 - accuracy: 0.9000 - val_loss: 0.5097 - val_accuracy: 0.7429\n",
            "Epoch 60/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3045 - accuracy: 0.9000 - val_loss: 0.5086 - val_accuracy: 0.7429\n",
            "Epoch 61/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3023 - accuracy: 0.9000 - val_loss: 0.5075 - val_accuracy: 0.7429\n",
            "Epoch 62/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.3003 - accuracy: 0.9000 - val_loss: 0.5064 - val_accuracy: 0.7429\n",
            "Epoch 63/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.2984 - accuracy: 0.9000 - val_loss: 0.5053 - val_accuracy: 0.7429\n",
            "Epoch 64/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2965 - accuracy: 0.9000 - val_loss: 0.5042 - val_accuracy: 0.7429\n",
            "Epoch 65/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.2946 - accuracy: 0.9000 - val_loss: 0.5031 - val_accuracy: 0.7429\n",
            "Epoch 66/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.2929 - accuracy: 0.9000 - val_loss: 0.5019 - val_accuracy: 0.7429\n",
            "Epoch 67/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.2912 - accuracy: 0.9000 - val_loss: 0.5008 - val_accuracy: 0.7429\n",
            "Epoch 68/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2896 - accuracy: 0.9000 - val_loss: 0.4997 - val_accuracy: 0.7429\n",
            "Epoch 69/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.2880 - accuracy: 0.9000 - val_loss: 0.4986 - val_accuracy: 0.7429\n",
            "Epoch 70/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2865 - accuracy: 0.9000 - val_loss: 0.4975 - val_accuracy: 0.7429\n",
            "Epoch 71/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2850 - accuracy: 0.9000 - val_loss: 0.4964 - val_accuracy: 0.7429\n",
            "Epoch 72/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.2836 - accuracy: 0.9000 - val_loss: 0.4953 - val_accuracy: 0.7429\n",
            "Epoch 73/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2822 - accuracy: 0.9000 - val_loss: 0.4942 - val_accuracy: 0.7429\n",
            "Epoch 74/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2808 - accuracy: 0.9000 - val_loss: 0.4931 - val_accuracy: 0.7429\n",
            "Epoch 75/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.2795 - accuracy: 0.9000 - val_loss: 0.4920 - val_accuracy: 0.7429\n",
            "Epoch 76/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.2783 - accuracy: 0.9000 - val_loss: 0.4909 - val_accuracy: 0.7429\n",
            "Epoch 77/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.2770 - accuracy: 0.9000 - val_loss: 0.4899 - val_accuracy: 0.7429\n",
            "Epoch 78/400\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.2758 - accuracy: 0.9000 - val_loss: 0.4889 - val_accuracy: 0.7429\n",
            "Epoch 79/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.2747 - accuracy: 0.9000 - val_loss: 0.4878 - val_accuracy: 0.7429\n",
            "Epoch 80/400\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.2735 - accuracy: 0.9000 - val_loss: 0.4868 - val_accuracy: 0.7429\n",
            "Epoch 81/400\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.2724 - accuracy: 0.9000 - val_loss: 0.4859 - val_accuracy: 0.7429\n",
            "Epoch 82/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.2713 - accuracy: 0.9000 - val_loss: 0.4849 - val_accuracy: 0.7429\n",
            "Epoch 83/400\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.2703 - accuracy: 0.9000 - val_loss: 0.4840 - val_accuracy: 0.7429\n",
            "Epoch 84/400\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.2693 - accuracy: 0.9000 - val_loss: 0.4830 - val_accuracy: 0.7429\n",
            "Epoch 85/400\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.2682 - accuracy: 0.9000 - val_loss: 0.4821 - val_accuracy: 0.7571\n",
            "Epoch 86/400\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.2672 - accuracy: 0.9000 - val_loss: 0.4811 - val_accuracy: 0.7571\n",
            "Epoch 87/400\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.2663 - accuracy: 0.9000 - val_loss: 0.4802 - val_accuracy: 0.7571\n",
            "Epoch 88/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.2653 - accuracy: 0.9000 - val_loss: 0.4793 - val_accuracy: 0.7571\n",
            "Epoch 89/400\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.2644 - accuracy: 0.9000 - val_loss: 0.4784 - val_accuracy: 0.7571\n",
            "Epoch 90/400\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.2634 - accuracy: 0.9000 - val_loss: 0.4775 - val_accuracy: 0.7571\n",
            "Epoch 91/400\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.2625 - accuracy: 0.9000 - val_loss: 0.4766 - val_accuracy: 0.7571\n",
            "Epoch 92/400\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.2616 - accuracy: 0.9000 - val_loss: 0.4758 - val_accuracy: 0.7571\n",
            "Epoch 93/400\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.2607 - accuracy: 0.9000 - val_loss: 0.4749 - val_accuracy: 0.7571\n",
            "Epoch 94/400\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.2599 - accuracy: 0.9000 - val_loss: 0.4740 - val_accuracy: 0.7571\n",
            "Epoch 95/400\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.2590 - accuracy: 0.9000 - val_loss: 0.4732 - val_accuracy: 0.7571\n",
            "Epoch 96/400\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.2582 - accuracy: 0.9000 - val_loss: 0.4724 - val_accuracy: 0.7571\n",
            "Epoch 97/400\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.2574 - accuracy: 0.9000 - val_loss: 0.4716 - val_accuracy: 0.7571\n",
            "Epoch 98/400\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.2566 - accuracy: 0.9000 - val_loss: 0.4708 - val_accuracy: 0.7571\n",
            "Epoch 99/400\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.2558 - accuracy: 0.9000 - val_loss: 0.4699 - val_accuracy: 0.7571\n",
            "Epoch 100/400\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.2550 - accuracy: 0.9000 - val_loss: 0.4691 - val_accuracy: 0.7571\n",
            "Epoch 101/400\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.2543 - accuracy: 0.9000 - val_loss: 0.4683 - val_accuracy: 0.7714\n",
            "Epoch 102/400\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.2535 - accuracy: 0.9000 - val_loss: 0.4675 - val_accuracy: 0.7714\n",
            "Epoch 103/400\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.2528 - accuracy: 0.9000 - val_loss: 0.4667 - val_accuracy: 0.7857\n",
            "Epoch 104/400\n",
            "1/1 [==============================] - 0s 242ms/step - loss: 0.2520 - accuracy: 0.9000 - val_loss: 0.4658 - val_accuracy: 0.7857\n",
            "Epoch 105/400\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.2513 - accuracy: 0.9000 - val_loss: 0.4650 - val_accuracy: 0.7857\n",
            "Epoch 106/400\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.2506 - accuracy: 0.9000 - val_loss: 0.4641 - val_accuracy: 0.7857\n",
            "Epoch 107/400\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.2499 - accuracy: 0.9000 - val_loss: 0.4633 - val_accuracy: 0.8000\n",
            "Epoch 108/400\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.2492 - accuracy: 0.9000 - val_loss: 0.4625 - val_accuracy: 0.8000\n",
            "Epoch 109/400\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.2485 - accuracy: 0.9000 - val_loss: 0.4616 - val_accuracy: 0.8000\n",
            "Epoch 110/400\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.2478 - accuracy: 0.9000 - val_loss: 0.4608 - val_accuracy: 0.8000\n",
            "Epoch 111/400\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.2472 - accuracy: 0.9000 - val_loss: 0.4599 - val_accuracy: 0.8000\n",
            "Epoch 112/400\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.2465 - accuracy: 0.9000 - val_loss: 0.4591 - val_accuracy: 0.8000\n",
            "Epoch 113/400\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.2459 - accuracy: 0.9000 - val_loss: 0.4582 - val_accuracy: 0.8143\n",
            "Epoch 114/400\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.2452 - accuracy: 0.9000 - val_loss: 0.4573 - val_accuracy: 0.8143\n",
            "Epoch 115/400\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.2446 - accuracy: 0.9000 - val_loss: 0.4565 - val_accuracy: 0.8143\n",
            "Epoch 116/400\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.2440 - accuracy: 0.9000 - val_loss: 0.4556 - val_accuracy: 0.8143\n",
            "Epoch 117/400\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.2434 - accuracy: 0.9333 - val_loss: 0.4548 - val_accuracy: 0.8143\n",
            "Epoch 118/400\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.2428 - accuracy: 0.9333 - val_loss: 0.4540 - val_accuracy: 0.8143\n",
            "Epoch 119/400\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.2422 - accuracy: 0.9333 - val_loss: 0.4532 - val_accuracy: 0.8143\n",
            "Epoch 120/400\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.2417 - accuracy: 0.9333 - val_loss: 0.4524 - val_accuracy: 0.8143\n",
            "Epoch 121/400\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.2411 - accuracy: 0.9333 - val_loss: 0.4516 - val_accuracy: 0.8143\n",
            "Epoch 122/400\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.2406 - accuracy: 0.9333 - val_loss: 0.4508 - val_accuracy: 0.8143\n",
            "Epoch 123/400\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.2400 - accuracy: 0.9333 - val_loss: 0.4500 - val_accuracy: 0.8143\n",
            "Epoch 124/400\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.2395 - accuracy: 0.9333 - val_loss: 0.4492 - val_accuracy: 0.8143\n",
            "Epoch 125/400\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.2389 - accuracy: 0.9333 - val_loss: 0.4485 - val_accuracy: 0.8143\n",
            "Epoch 126/400\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.2384 - accuracy: 0.9333 - val_loss: 0.4477 - val_accuracy: 0.8143\n",
            "Epoch 127/400\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.2379 - accuracy: 0.9333 - val_loss: 0.4470 - val_accuracy: 0.8143\n",
            "Epoch 128/400\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.2374 - accuracy: 0.9333 - val_loss: 0.4463 - val_accuracy: 0.8286\n",
            "Epoch 129/400\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.2369 - accuracy: 0.9333 - val_loss: 0.4456 - val_accuracy: 0.8286\n",
            "Epoch 130/400\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.2364 - accuracy: 0.9333 - val_loss: 0.4449 - val_accuracy: 0.8286\n",
            "Epoch 131/400\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.2360 - accuracy: 0.9333 - val_loss: 0.4443 - val_accuracy: 0.8286\n",
            "Epoch 132/400\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.2355 - accuracy: 0.9333 - val_loss: 0.4436 - val_accuracy: 0.8286\n",
            "Epoch 133/400\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.2350 - accuracy: 0.9333 - val_loss: 0.4430 - val_accuracy: 0.8286\n",
            "Epoch 134/400\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.2346 - accuracy: 0.9333 - val_loss: 0.4423 - val_accuracy: 0.8286\n",
            "Epoch 135/400\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.2341 - accuracy: 0.9333 - val_loss: 0.4417 - val_accuracy: 0.8286\n",
            "Epoch 136/400\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.2337 - accuracy: 0.9333 - val_loss: 0.4412 - val_accuracy: 0.8286\n",
            "Epoch 137/400\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.2332 - accuracy: 0.9333 - val_loss: 0.4406 - val_accuracy: 0.8286\n",
            "Epoch 138/400\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.2328 - accuracy: 0.9333 - val_loss: 0.4400 - val_accuracy: 0.8286\n",
            "Epoch 139/400\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.2324 - accuracy: 0.9333 - val_loss: 0.4395 - val_accuracy: 0.8286\n",
            "Epoch 140/400\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.2320 - accuracy: 0.9667 - val_loss: 0.4389 - val_accuracy: 0.8286\n",
            "Epoch 141/400\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.2315 - accuracy: 0.9667 - val_loss: 0.4384 - val_accuracy: 0.8286\n",
            "Epoch 142/400\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.2311 - accuracy: 0.9667 - val_loss: 0.4378 - val_accuracy: 0.8286\n",
            "Epoch 143/400\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.2307 - accuracy: 0.9667 - val_loss: 0.4373 - val_accuracy: 0.8286\n",
            "Epoch 144/400\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.2303 - accuracy: 0.9667 - val_loss: 0.4368 - val_accuracy: 0.8286\n",
            "Epoch 145/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.2299 - accuracy: 0.9667 - val_loss: 0.4363 - val_accuracy: 0.8286\n",
            "Epoch 146/400\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.2295 - accuracy: 0.9667 - val_loss: 0.4358 - val_accuracy: 0.8286\n",
            "Epoch 147/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.2291 - accuracy: 0.9667 - val_loss: 0.4353 - val_accuracy: 0.8286\n",
            "Epoch 148/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.2287 - accuracy: 0.9667 - val_loss: 0.4348 - val_accuracy: 0.8286\n",
            "Epoch 149/400\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.2283 - accuracy: 0.9667 - val_loss: 0.4343 - val_accuracy: 0.8286\n",
            "Epoch 150/400\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.2280 - accuracy: 0.9667 - val_loss: 0.4339 - val_accuracy: 0.8286\n",
            "Epoch 151/400\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.2276 - accuracy: 0.9667 - val_loss: 0.4334 - val_accuracy: 0.8286\n",
            "Epoch 152/400\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.2272 - accuracy: 0.9667 - val_loss: 0.4330 - val_accuracy: 0.8286\n",
            "Epoch 153/400\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.2268 - accuracy: 0.9667 - val_loss: 0.4325 - val_accuracy: 0.8286\n",
            "Epoch 154/400\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.2265 - accuracy: 0.9667 - val_loss: 0.4321 - val_accuracy: 0.8286\n",
            "Epoch 155/400\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.2261 - accuracy: 0.9667 - val_loss: 0.4316 - val_accuracy: 0.8286\n",
            "Epoch 156/400\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.2258 - accuracy: 0.9667 - val_loss: 0.4312 - val_accuracy: 0.8286\n",
            "Epoch 157/400\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.2254 - accuracy: 0.9667 - val_loss: 0.4308 - val_accuracy: 0.8286\n",
            "Epoch 158/400\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.2251 - accuracy: 0.9667 - val_loss: 0.4304 - val_accuracy: 0.8286\n",
            "Epoch 159/400\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.2247 - accuracy: 0.9667 - val_loss: 0.4300 - val_accuracy: 0.8286\n",
            "Epoch 160/400\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.2244 - accuracy: 0.9667 - val_loss: 0.4296 - val_accuracy: 0.8286\n",
            "Epoch 161/400\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.2240 - accuracy: 0.9667 - val_loss: 0.4292 - val_accuracy: 0.8286\n",
            "Epoch 162/400\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.2237 - accuracy: 0.9667 - val_loss: 0.4288 - val_accuracy: 0.8286\n",
            "Epoch 163/400\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.2233 - accuracy: 0.9667 - val_loss: 0.4285 - val_accuracy: 0.8286\n",
            "Epoch 164/400\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.2230 - accuracy: 0.9667 - val_loss: 0.4281 - val_accuracy: 0.8286\n",
            "Epoch 165/400\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.2227 - accuracy: 0.9667 - val_loss: 0.4277 - val_accuracy: 0.8286\n",
            "Epoch 166/400\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.2224 - accuracy: 0.9667 - val_loss: 0.4273 - val_accuracy: 0.8286\n",
            "Epoch 167/400\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.2220 - accuracy: 0.9667 - val_loss: 0.4269 - val_accuracy: 0.8286\n",
            "Epoch 168/400\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.2217 - accuracy: 0.9667 - val_loss: 0.4265 - val_accuracy: 0.8286\n",
            "Epoch 169/400\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.2214 - accuracy: 0.9667 - val_loss: 0.4262 - val_accuracy: 0.8286\n",
            "Epoch 170/400\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.2211 - accuracy: 0.9667 - val_loss: 0.4258 - val_accuracy: 0.8286\n",
            "Epoch 171/400\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.2208 - accuracy: 0.9667 - val_loss: 0.4255 - val_accuracy: 0.8286\n",
            "Epoch 172/400\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.2205 - accuracy: 0.9667 - val_loss: 0.4252 - val_accuracy: 0.8286\n",
            "Epoch 173/400\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.2202 - accuracy: 0.9667 - val_loss: 0.4249 - val_accuracy: 0.8286\n",
            "Epoch 174/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.2199 - accuracy: 0.9667 - val_loss: 0.4245 - val_accuracy: 0.8286\n",
            "Epoch 175/400\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.2196 - accuracy: 0.9667 - val_loss: 0.4242 - val_accuracy: 0.8286\n",
            "Epoch 176/400\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.2193 - accuracy: 0.9667 - val_loss: 0.4239 - val_accuracy: 0.8286\n",
            "Epoch 177/400\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.2190 - accuracy: 0.9667 - val_loss: 0.4235 - val_accuracy: 0.8286\n",
            "Epoch 178/400\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.2187 - accuracy: 0.9667 - val_loss: 0.4232 - val_accuracy: 0.8286\n",
            "Epoch 179/400\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.2184 - accuracy: 0.9667 - val_loss: 0.4229 - val_accuracy: 0.8286\n",
            "Epoch 180/400\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.2182 - accuracy: 0.9667 - val_loss: 0.4226 - val_accuracy: 0.8286\n",
            "Epoch 181/400\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.2179 - accuracy: 0.9667 - val_loss: 0.4224 - val_accuracy: 0.8286\n",
            "Epoch 182/400\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.2176 - accuracy: 0.9667 - val_loss: 0.4221 - val_accuracy: 0.8286\n",
            "Epoch 183/400\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.2173 - accuracy: 0.9667 - val_loss: 0.4219 - val_accuracy: 0.8286\n",
            "Epoch 184/400\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.2171 - accuracy: 0.9667 - val_loss: 0.4216 - val_accuracy: 0.8286\n",
            "Epoch 185/400\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.2168 - accuracy: 0.9667 - val_loss: 0.4213 - val_accuracy: 0.8286\n",
            "Epoch 186/400\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.2165 - accuracy: 0.9667 - val_loss: 0.4211 - val_accuracy: 0.8286\n",
            "Epoch 187/400\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.2163 - accuracy: 0.9667 - val_loss: 0.4208 - val_accuracy: 0.8286\n",
            "Epoch 188/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.2160 - accuracy: 0.9667 - val_loss: 0.4206 - val_accuracy: 0.8286\n",
            "Epoch 189/400\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.2158 - accuracy: 0.9667 - val_loss: 0.4203 - val_accuracy: 0.8286\n",
            "Epoch 190/400\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.2155 - accuracy: 0.9667 - val_loss: 0.4201 - val_accuracy: 0.8286\n",
            "Epoch 191/400\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.2152 - accuracy: 0.9667 - val_loss: 0.4199 - val_accuracy: 0.8286\n",
            "Epoch 192/400\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.2150 - accuracy: 0.9667 - val_loss: 0.4196 - val_accuracy: 0.8286\n",
            "Epoch 193/400\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.2147 - accuracy: 0.9667 - val_loss: 0.4194 - val_accuracy: 0.8286\n",
            "Epoch 194/400\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.2145 - accuracy: 0.9667 - val_loss: 0.4192 - val_accuracy: 0.8286\n",
            "Epoch 195/400\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.2142 - accuracy: 0.9667 - val_loss: 0.4190 - val_accuracy: 0.8286\n",
            "Epoch 196/400\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.2140 - accuracy: 0.9667 - val_loss: 0.4188 - val_accuracy: 0.8286\n",
            "Epoch 197/400\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.2138 - accuracy: 0.9667 - val_loss: 0.4186 - val_accuracy: 0.8286\n",
            "Epoch 198/400\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.2135 - accuracy: 0.9667 - val_loss: 0.4184 - val_accuracy: 0.8286\n",
            "Epoch 199/400\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.2133 - accuracy: 0.9667 - val_loss: 0.4182 - val_accuracy: 0.8286\n",
            "Epoch 200/400\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.2130 - accuracy: 0.9667 - val_loss: 0.4180 - val_accuracy: 0.8286\n",
            "Epoch 201/400\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.2128 - accuracy: 0.9667 - val_loss: 0.4177 - val_accuracy: 0.8286\n",
            "Epoch 202/400\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.2126 - accuracy: 0.9667 - val_loss: 0.4175 - val_accuracy: 0.8286\n",
            "Epoch 203/400\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.2124 - accuracy: 0.9667 - val_loss: 0.4173 - val_accuracy: 0.8286\n",
            "Epoch 204/400\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.2121 - accuracy: 0.9667 - val_loss: 0.4170 - val_accuracy: 0.8286\n",
            "Epoch 205/400\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.2119 - accuracy: 0.9667 - val_loss: 0.4168 - val_accuracy: 0.8286\n",
            "Epoch 206/400\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.2117 - accuracy: 0.9667 - val_loss: 0.4166 - val_accuracy: 0.8286\n",
            "Epoch 207/400\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.2115 - accuracy: 0.9667 - val_loss: 0.4164 - val_accuracy: 0.8286\n",
            "Epoch 208/400\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.2113 - accuracy: 0.9667 - val_loss: 0.4162 - val_accuracy: 0.8286\n",
            "Epoch 209/400\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.2110 - accuracy: 0.9667 - val_loss: 0.4160 - val_accuracy: 0.8286\n",
            "Epoch 210/400\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.2108 - accuracy: 0.9667 - val_loss: 0.4158 - val_accuracy: 0.8286\n",
            "Epoch 211/400\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.2106 - accuracy: 0.9667 - val_loss: 0.4157 - val_accuracy: 0.8286\n",
            "Epoch 212/400\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.2104 - accuracy: 0.9667 - val_loss: 0.4155 - val_accuracy: 0.8286\n",
            "Epoch 213/400\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.2102 - accuracy: 0.9667 - val_loss: 0.4153 - val_accuracy: 0.8286\n",
            "Epoch 214/400\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.2100 - accuracy: 0.9667 - val_loss: 0.4150 - val_accuracy: 0.8286\n",
            "Epoch 215/400\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.2098 - accuracy: 0.9667 - val_loss: 0.4149 - val_accuracy: 0.8286\n",
            "Epoch 216/400\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.2096 - accuracy: 0.9667 - val_loss: 0.4147 - val_accuracy: 0.8286\n",
            "Epoch 217/400\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 0.2094 - accuracy: 0.9667 - val_loss: 0.4145 - val_accuracy: 0.8286\n",
            "Epoch 218/400\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.2092 - accuracy: 0.9667 - val_loss: 0.4143 - val_accuracy: 0.8286\n",
            "Epoch 219/400\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.2089 - accuracy: 0.9667 - val_loss: 0.4141 - val_accuracy: 0.8286\n",
            "Epoch 220/400\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.2087 - accuracy: 0.9667 - val_loss: 0.4139 - val_accuracy: 0.8286\n",
            "Epoch 221/400\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.2085 - accuracy: 0.9667 - val_loss: 0.4137 - val_accuracy: 0.8286\n",
            "Epoch 222/400\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.2084 - accuracy: 0.9667 - val_loss: 0.4136 - val_accuracy: 0.8286\n",
            "Epoch 223/400\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.2082 - accuracy: 0.9667 - val_loss: 0.4134 - val_accuracy: 0.8286\n",
            "Epoch 224/400\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.2080 - accuracy: 0.9667 - val_loss: 0.4132 - val_accuracy: 0.8286\n",
            "Epoch 225/400\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.2078 - accuracy: 0.9667 - val_loss: 0.4131 - val_accuracy: 0.8286\n",
            "Epoch 226/400\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.2076 - accuracy: 0.9667 - val_loss: 0.4129 - val_accuracy: 0.8286\n",
            "Epoch 227/400\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.2074 - accuracy: 0.9667 - val_loss: 0.4128 - val_accuracy: 0.8286\n",
            "Epoch 228/400\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.2072 - accuracy: 0.9667 - val_loss: 0.4126 - val_accuracy: 0.8286\n",
            "Epoch 229/400\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.2070 - accuracy: 0.9667 - val_loss: 0.4125 - val_accuracy: 0.8286\n",
            "Epoch 230/400\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.2068 - accuracy: 0.9667 - val_loss: 0.4123 - val_accuracy: 0.8286\n",
            "Epoch 231/400\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.2066 - accuracy: 0.9667 - val_loss: 0.4122 - val_accuracy: 0.8286\n",
            "Epoch 232/400\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.2064 - accuracy: 0.9667 - val_loss: 0.4120 - val_accuracy: 0.8286\n",
            "Epoch 233/400\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.2063 - accuracy: 0.9667 - val_loss: 0.4118 - val_accuracy: 0.8286\n",
            "Epoch 234/400\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.2061 - accuracy: 0.9667 - val_loss: 0.4116 - val_accuracy: 0.8286\n",
            "Epoch 235/400\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.2059 - accuracy: 0.9667 - val_loss: 0.4115 - val_accuracy: 0.8286\n",
            "Epoch 236/400\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.2057 - accuracy: 0.9667 - val_loss: 0.4113 - val_accuracy: 0.8286\n",
            "Epoch 237/400\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.2055 - accuracy: 0.9667 - val_loss: 0.4111 - val_accuracy: 0.8286\n",
            "Epoch 238/400\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.2054 - accuracy: 0.9667 - val_loss: 0.4109 - val_accuracy: 0.8286\n",
            "Epoch 239/400\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.2052 - accuracy: 0.9667 - val_loss: 0.4108 - val_accuracy: 0.8286\n",
            "Epoch 240/400\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.2050 - accuracy: 0.9667 - val_loss: 0.4106 - val_accuracy: 0.8286\n",
            "Epoch 241/400\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.2048 - accuracy: 0.9667 - val_loss: 0.4104 - val_accuracy: 0.8286\n",
            "Epoch 242/400\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.2047 - accuracy: 0.9667 - val_loss: 0.4103 - val_accuracy: 0.8286\n",
            "Epoch 243/400\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.2045 - accuracy: 0.9667 - val_loss: 0.4101 - val_accuracy: 0.8286\n",
            "Epoch 244/400\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.2044 - accuracy: 0.9667 - val_loss: 0.4100 - val_accuracy: 0.8286\n",
            "Epoch 245/400\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.2042 - accuracy: 0.9667 - val_loss: 0.4098 - val_accuracy: 0.8286\n",
            "Epoch 246/400\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.2040 - accuracy: 0.9667 - val_loss: 0.4097 - val_accuracy: 0.8286\n",
            "Epoch 247/400\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.2039 - accuracy: 0.9667 - val_loss: 0.4096 - val_accuracy: 0.8286\n",
            "Epoch 248/400\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.2037 - accuracy: 0.9667 - val_loss: 0.4095 - val_accuracy: 0.8286\n",
            "Epoch 249/400\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.2035 - accuracy: 0.9667 - val_loss: 0.4093 - val_accuracy: 0.8286\n",
            "Epoch 250/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2034 - accuracy: 0.9667 - val_loss: 0.4092 - val_accuracy: 0.8286\n",
            "Epoch 251/400\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.2032 - accuracy: 0.9667 - val_loss: 0.4091 - val_accuracy: 0.8286\n",
            "Epoch 252/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.2031 - accuracy: 0.9667 - val_loss: 0.4090 - val_accuracy: 0.8286\n",
            "Epoch 253/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2029 - accuracy: 0.9667 - val_loss: 0.4089 - val_accuracy: 0.8286\n",
            "Epoch 254/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.2028 - accuracy: 0.9667 - val_loss: 0.4088 - val_accuracy: 0.8286\n",
            "Epoch 255/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2026 - accuracy: 0.9667 - val_loss: 0.4087 - val_accuracy: 0.8286\n",
            "Epoch 256/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2025 - accuracy: 0.9667 - val_loss: 0.4086 - val_accuracy: 0.8286\n",
            "Epoch 257/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.2023 - accuracy: 0.9667 - val_loss: 0.4085 - val_accuracy: 0.8286\n",
            "Epoch 258/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2022 - accuracy: 0.9667 - val_loss: 0.4085 - val_accuracy: 0.8286\n",
            "Epoch 259/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2020 - accuracy: 0.9667 - val_loss: 0.4084 - val_accuracy: 0.8286\n",
            "Epoch 260/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2019 - accuracy: 0.9667 - val_loss: 0.4083 - val_accuracy: 0.8286\n",
            "Epoch 261/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2017 - accuracy: 0.9667 - val_loss: 0.4082 - val_accuracy: 0.8286\n",
            "Epoch 262/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.2016 - accuracy: 0.9667 - val_loss: 0.4081 - val_accuracy: 0.8286\n",
            "Epoch 263/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.2014 - accuracy: 0.9667 - val_loss: 0.4080 - val_accuracy: 0.8286\n",
            "Epoch 264/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.2013 - accuracy: 0.9667 - val_loss: 0.4079 - val_accuracy: 0.8286\n",
            "Epoch 265/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.2011 - accuracy: 0.9667 - val_loss: 0.4078 - val_accuracy: 0.8286\n",
            "Epoch 266/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.2010 - accuracy: 0.9667 - val_loss: 0.4077 - val_accuracy: 0.8286\n",
            "Epoch 267/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.2008 - accuracy: 0.9667 - val_loss: 0.4076 - val_accuracy: 0.8286\n",
            "Epoch 268/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.2007 - accuracy: 0.9667 - val_loss: 0.4075 - val_accuracy: 0.8286\n",
            "Epoch 269/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.2005 - accuracy: 0.9667 - val_loss: 0.4074 - val_accuracy: 0.8286\n",
            "Epoch 270/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.2004 - accuracy: 0.9667 - val_loss: 0.4073 - val_accuracy: 0.8286\n",
            "Epoch 271/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.2003 - accuracy: 0.9667 - val_loss: 0.4072 - val_accuracy: 0.8286\n",
            "Epoch 272/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.2001 - accuracy: 0.9667 - val_loss: 0.4071 - val_accuracy: 0.8143\n",
            "Epoch 273/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.2000 - accuracy: 0.9667 - val_loss: 0.4069 - val_accuracy: 0.8143\n",
            "Epoch 274/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.1998 - accuracy: 0.9667 - val_loss: 0.4068 - val_accuracy: 0.8143\n",
            "Epoch 275/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.1997 - accuracy: 0.9667 - val_loss: 0.4067 - val_accuracy: 0.8143\n",
            "Epoch 276/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1996 - accuracy: 0.9667 - val_loss: 0.4065 - val_accuracy: 0.8143\n",
            "Epoch 277/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.1994 - accuracy: 0.9667 - val_loss: 0.4064 - val_accuracy: 0.8143\n",
            "Epoch 278/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1993 - accuracy: 0.9667 - val_loss: 0.4063 - val_accuracy: 0.8143\n",
            "Epoch 279/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.1991 - accuracy: 0.9667 - val_loss: 0.4062 - val_accuracy: 0.8143\n",
            "Epoch 280/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.1990 - accuracy: 0.9667 - val_loss: 0.4061 - val_accuracy: 0.8143\n",
            "Epoch 281/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1989 - accuracy: 0.9667 - val_loss: 0.4060 - val_accuracy: 0.8143\n",
            "Epoch 282/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.1987 - accuracy: 0.9667 - val_loss: 0.4059 - val_accuracy: 0.8143\n",
            "Epoch 283/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1986 - accuracy: 0.9667 - val_loss: 0.4058 - val_accuracy: 0.8143\n",
            "Epoch 284/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1985 - accuracy: 0.9667 - val_loss: 0.4056 - val_accuracy: 0.8143\n",
            "Epoch 285/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.1983 - accuracy: 0.9667 - val_loss: 0.4055 - val_accuracy: 0.8143\n",
            "Epoch 286/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.1982 - accuracy: 0.9667 - val_loss: 0.4054 - val_accuracy: 0.8143\n",
            "Epoch 287/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1981 - accuracy: 0.9667 - val_loss: 0.4052 - val_accuracy: 0.8143\n",
            "Epoch 288/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1979 - accuracy: 0.9667 - val_loss: 0.4051 - val_accuracy: 0.8143\n",
            "Epoch 289/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1978 - accuracy: 0.9667 - val_loss: 0.4050 - val_accuracy: 0.8143\n",
            "Epoch 290/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1977 - accuracy: 0.9667 - val_loss: 0.4049 - val_accuracy: 0.8143\n",
            "Epoch 291/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1975 - accuracy: 0.9667 - val_loss: 0.4048 - val_accuracy: 0.8143\n",
            "Epoch 292/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.1974 - accuracy: 0.9667 - val_loss: 0.4047 - val_accuracy: 0.8143\n",
            "Epoch 293/400\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.1973 - accuracy: 0.9667 - val_loss: 0.4046 - val_accuracy: 0.8143\n",
            "Epoch 294/400\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.1972 - accuracy: 0.9667 - val_loss: 0.4045 - val_accuracy: 0.8143\n",
            "Epoch 295/400\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.1970 - accuracy: 0.9667 - val_loss: 0.4044 - val_accuracy: 0.8143\n",
            "Epoch 296/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.1969 - accuracy: 0.9667 - val_loss: 0.4043 - val_accuracy: 0.8143\n",
            "Epoch 297/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.1968 - accuracy: 0.9667 - val_loss: 0.4042 - val_accuracy: 0.8143\n",
            "Epoch 298/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1967 - accuracy: 0.9667 - val_loss: 0.4041 - val_accuracy: 0.8143\n",
            "Epoch 299/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.1965 - accuracy: 0.9667 - val_loss: 0.4041 - val_accuracy: 0.8143\n",
            "Epoch 300/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.1964 - accuracy: 0.9667 - val_loss: 0.4040 - val_accuracy: 0.8143\n",
            "Epoch 301/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1963 - accuracy: 0.9667 - val_loss: 0.4039 - val_accuracy: 0.8143\n",
            "Epoch 302/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1962 - accuracy: 0.9667 - val_loss: 0.4039 - val_accuracy: 0.8143\n",
            "Epoch 303/400\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.1960 - accuracy: 0.9667 - val_loss: 0.4038 - val_accuracy: 0.8143\n",
            "Epoch 304/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1959 - accuracy: 0.9667 - val_loss: 0.4037 - val_accuracy: 0.8143\n",
            "Epoch 305/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.1958 - accuracy: 0.9667 - val_loss: 0.4035 - val_accuracy: 0.8143\n",
            "Epoch 306/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.1957 - accuracy: 0.9667 - val_loss: 0.4034 - val_accuracy: 0.8143\n",
            "Epoch 307/400\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.1955 - accuracy: 0.9667 - val_loss: 0.4033 - val_accuracy: 0.8143\n",
            "Epoch 308/400\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.1954 - accuracy: 0.9667 - val_loss: 0.4032 - val_accuracy: 0.8143\n",
            "Epoch 309/400\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.1953 - accuracy: 0.9667 - val_loss: 0.4031 - val_accuracy: 0.8143\n",
            "Epoch 310/400\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.1952 - accuracy: 0.9667 - val_loss: 0.4031 - val_accuracy: 0.8143\n",
            "Epoch 311/400\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.1951 - accuracy: 0.9667 - val_loss: 0.4030 - val_accuracy: 0.8143\n",
            "Epoch 312/400\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.1949 - accuracy: 0.9667 - val_loss: 0.4028 - val_accuracy: 0.8143\n",
            "Epoch 313/400\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.1948 - accuracy: 0.9667 - val_loss: 0.4027 - val_accuracy: 0.8143\n",
            "Epoch 314/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.1947 - accuracy: 0.9667 - val_loss: 0.4026 - val_accuracy: 0.8143\n",
            "Epoch 315/400\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.1946 - accuracy: 0.9667 - val_loss: 0.4025 - val_accuracy: 0.8143\n",
            "Epoch 316/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1945 - accuracy: 0.9667 - val_loss: 0.4024 - val_accuracy: 0.8143\n",
            "Epoch 317/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1943 - accuracy: 0.9667 - val_loss: 0.4023 - val_accuracy: 0.8143\n",
            "Epoch 318/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.1942 - accuracy: 0.9667 - val_loss: 0.4022 - val_accuracy: 0.8143\n",
            "Epoch 319/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.1941 - accuracy: 0.9667 - val_loss: 0.4021 - val_accuracy: 0.8143\n",
            "Epoch 320/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1940 - accuracy: 0.9667 - val_loss: 0.4020 - val_accuracy: 0.8143\n",
            "Epoch 321/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1939 - accuracy: 0.9667 - val_loss: 0.4019 - val_accuracy: 0.8143\n",
            "Epoch 322/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1938 - accuracy: 0.9667 - val_loss: 0.4018 - val_accuracy: 0.8143\n",
            "Epoch 323/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1936 - accuracy: 0.9667 - val_loss: 0.4018 - val_accuracy: 0.8143\n",
            "Epoch 324/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1935 - accuracy: 0.9667 - val_loss: 0.4017 - val_accuracy: 0.8143\n",
            "Epoch 325/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1934 - accuracy: 0.9667 - val_loss: 0.4016 - val_accuracy: 0.8143\n",
            "Epoch 326/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.1933 - accuracy: 0.9667 - val_loss: 0.4015 - val_accuracy: 0.8143\n",
            "Epoch 327/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1932 - accuracy: 0.9667 - val_loss: 0.4014 - val_accuracy: 0.8143\n",
            "Epoch 328/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1931 - accuracy: 0.9667 - val_loss: 0.4013 - val_accuracy: 0.8143\n",
            "Epoch 329/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1930 - accuracy: 0.9667 - val_loss: 0.4012 - val_accuracy: 0.8143\n",
            "Epoch 330/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.1928 - accuracy: 0.9667 - val_loss: 0.4011 - val_accuracy: 0.8143\n",
            "Epoch 331/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.1927 - accuracy: 0.9667 - val_loss: 0.4010 - val_accuracy: 0.8143\n",
            "Epoch 332/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.1926 - accuracy: 0.9667 - val_loss: 0.4010 - val_accuracy: 0.8143\n",
            "Epoch 333/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1925 - accuracy: 0.9667 - val_loss: 0.4009 - val_accuracy: 0.8143\n",
            "Epoch 334/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1924 - accuracy: 0.9667 - val_loss: 0.4008 - val_accuracy: 0.8143\n",
            "Epoch 335/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.1923 - accuracy: 0.9667 - val_loss: 0.4007 - val_accuracy: 0.8143\n",
            "Epoch 336/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1922 - accuracy: 0.9667 - val_loss: 0.4006 - val_accuracy: 0.8143\n",
            "Epoch 337/400\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.1921 - accuracy: 0.9667 - val_loss: 0.4005 - val_accuracy: 0.8143\n",
            "Epoch 338/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1920 - accuracy: 0.9667 - val_loss: 0.4004 - val_accuracy: 0.8143\n",
            "Epoch 339/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.1918 - accuracy: 0.9667 - val_loss: 0.4003 - val_accuracy: 0.8143\n",
            "Epoch 340/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.1917 - accuracy: 0.9667 - val_loss: 0.4002 - val_accuracy: 0.8143\n",
            "Epoch 341/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.1916 - accuracy: 0.9667 - val_loss: 0.4001 - val_accuracy: 0.8143\n",
            "Epoch 342/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.1915 - accuracy: 0.9667 - val_loss: 0.4000 - val_accuracy: 0.8143\n",
            "Epoch 343/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.1914 - accuracy: 0.9667 - val_loss: 0.3999 - val_accuracy: 0.8143\n",
            "Epoch 344/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.1913 - accuracy: 0.9667 - val_loss: 0.3998 - val_accuracy: 0.8143\n",
            "Epoch 345/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.1912 - accuracy: 0.9667 - val_loss: 0.3997 - val_accuracy: 0.8143\n",
            "Epoch 346/400\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.1911 - accuracy: 0.9667 - val_loss: 0.3996 - val_accuracy: 0.8143\n",
            "Epoch 347/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1910 - accuracy: 0.9667 - val_loss: 0.3995 - val_accuracy: 0.8143\n",
            "Epoch 348/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.1909 - accuracy: 0.9667 - val_loss: 0.3994 - val_accuracy: 0.8143\n",
            "Epoch 349/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.1908 - accuracy: 0.9667 - val_loss: 0.3993 - val_accuracy: 0.8143\n",
            "Epoch 350/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.1906 - accuracy: 0.9667 - val_loss: 0.3992 - val_accuracy: 0.8143\n",
            "Epoch 351/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.1905 - accuracy: 0.9667 - val_loss: 0.3992 - val_accuracy: 0.8143\n",
            "Epoch 352/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1904 - accuracy: 0.9667 - val_loss: 0.3991 - val_accuracy: 0.8143\n",
            "Epoch 353/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.1903 - accuracy: 0.9667 - val_loss: 0.3989 - val_accuracy: 0.8143\n",
            "Epoch 354/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.1902 - accuracy: 0.9667 - val_loss: 0.3988 - val_accuracy: 0.8143\n",
            "Epoch 355/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1901 - accuracy: 0.9667 - val_loss: 0.3987 - val_accuracy: 0.8143\n",
            "Epoch 356/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.1900 - accuracy: 0.9667 - val_loss: 0.3986 - val_accuracy: 0.8143\n",
            "Epoch 357/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.1899 - accuracy: 0.9667 - val_loss: 0.3985 - val_accuracy: 0.8143\n",
            "Epoch 358/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1898 - accuracy: 0.9667 - val_loss: 0.3984 - val_accuracy: 0.8143\n",
            "Epoch 359/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1897 - accuracy: 0.9667 - val_loss: 0.3984 - val_accuracy: 0.8143\n",
            "Epoch 360/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1896 - accuracy: 0.9667 - val_loss: 0.3982 - val_accuracy: 0.8143\n",
            "Epoch 361/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.1895 - accuracy: 0.9667 - val_loss: 0.3981 - val_accuracy: 0.8143\n",
            "Epoch 362/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.1894 - accuracy: 0.9667 - val_loss: 0.3980 - val_accuracy: 0.8143\n",
            "Epoch 363/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1893 - accuracy: 0.9667 - val_loss: 0.3980 - val_accuracy: 0.8143\n",
            "Epoch 364/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.1892 - accuracy: 0.9667 - val_loss: 0.3979 - val_accuracy: 0.8143\n",
            "Epoch 365/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.1891 - accuracy: 0.9667 - val_loss: 0.3978 - val_accuracy: 0.8143\n",
            "Epoch 366/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.1890 - accuracy: 0.9667 - val_loss: 0.3978 - val_accuracy: 0.8143\n",
            "Epoch 367/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.1889 - accuracy: 0.9667 - val_loss: 0.3977 - val_accuracy: 0.8143\n",
            "Epoch 368/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.1888 - accuracy: 0.9667 - val_loss: 0.3976 - val_accuracy: 0.8143\n",
            "Epoch 369/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.1887 - accuracy: 0.9667 - val_loss: 0.3975 - val_accuracy: 0.8143\n",
            "Epoch 370/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.1886 - accuracy: 0.9667 - val_loss: 0.3974 - val_accuracy: 0.8143\n",
            "Epoch 371/400\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.1885 - accuracy: 0.9667 - val_loss: 0.3973 - val_accuracy: 0.8143\n",
            "Epoch 372/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1884 - accuracy: 0.9667 - val_loss: 0.3972 - val_accuracy: 0.8143\n",
            "Epoch 373/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.1883 - accuracy: 0.9667 - val_loss: 0.3971 - val_accuracy: 0.8143\n",
            "Epoch 374/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.1882 - accuracy: 0.9667 - val_loss: 0.3970 - val_accuracy: 0.8143\n",
            "Epoch 375/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.1881 - accuracy: 0.9667 - val_loss: 0.3970 - val_accuracy: 0.8143\n",
            "Epoch 376/400\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.1880 - accuracy: 0.9667 - val_loss: 0.3969 - val_accuracy: 0.8143\n",
            "Epoch 377/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1879 - accuracy: 0.9667 - val_loss: 0.3968 - val_accuracy: 0.8143\n",
            "Epoch 378/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.1878 - accuracy: 0.9667 - val_loss: 0.3967 - val_accuracy: 0.8143\n",
            "Epoch 379/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.1877 - accuracy: 0.9667 - val_loss: 0.3966 - val_accuracy: 0.8143\n",
            "Epoch 380/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.1876 - accuracy: 0.9667 - val_loss: 0.3965 - val_accuracy: 0.8143\n",
            "Epoch 381/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1875 - accuracy: 0.9667 - val_loss: 0.3964 - val_accuracy: 0.8143\n",
            "Epoch 382/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1874 - accuracy: 0.9667 - val_loss: 0.3964 - val_accuracy: 0.8143\n",
            "Epoch 383/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.1873 - accuracy: 0.9667 - val_loss: 0.3963 - val_accuracy: 0.8143\n",
            "Epoch 384/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.1872 - accuracy: 0.9667 - val_loss: 0.3963 - val_accuracy: 0.8143\n",
            "Epoch 385/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1871 - accuracy: 0.9667 - val_loss: 0.3962 - val_accuracy: 0.8143\n",
            "Epoch 386/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.1870 - accuracy: 0.9667 - val_loss: 0.3961 - val_accuracy: 0.8143\n",
            "Epoch 387/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.1869 - accuracy: 0.9667 - val_loss: 0.3960 - val_accuracy: 0.8143\n",
            "Epoch 388/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1868 - accuracy: 0.9667 - val_loss: 0.3959 - val_accuracy: 0.8143\n",
            "Epoch 389/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.1867 - accuracy: 0.9667 - val_loss: 0.3958 - val_accuracy: 0.8143\n",
            "Epoch 390/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1866 - accuracy: 0.9667 - val_loss: 0.3957 - val_accuracy: 0.8143\n",
            "Epoch 391/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.1865 - accuracy: 0.9667 - val_loss: 0.3956 - val_accuracy: 0.8143\n",
            "Epoch 392/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1864 - accuracy: 0.9667 - val_loss: 0.3956 - val_accuracy: 0.8143\n",
            "Epoch 393/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1863 - accuracy: 0.9667 - val_loss: 0.3956 - val_accuracy: 0.8143\n",
            "Epoch 394/400\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.1862 - accuracy: 0.9667 - val_loss: 0.3955 - val_accuracy: 0.8143\n",
            "Epoch 395/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.1861 - accuracy: 0.9667 - val_loss: 0.3954 - val_accuracy: 0.8143\n",
            "Epoch 396/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.1860 - accuracy: 0.9667 - val_loss: 0.3952 - val_accuracy: 0.8143\n",
            "Epoch 397/400\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.1859 - accuracy: 0.9667 - val_loss: 0.3951 - val_accuracy: 0.8143\n",
            "Epoch 398/400\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.1859 - accuracy: 0.9667 - val_loss: 0.3950 - val_accuracy: 0.8143\n",
            "Epoch 399/400\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.1858 - accuracy: 0.9667 - val_loss: 0.3950 - val_accuracy: 0.8143\n",
            "Epoch 400/400\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.1857 - accuracy: 0.9667 - val_loss: 0.3949 - val_accuracy: 0.8143\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}