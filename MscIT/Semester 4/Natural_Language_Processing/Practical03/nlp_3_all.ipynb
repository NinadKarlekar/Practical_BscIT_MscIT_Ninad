{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP 3A. Study of Wordnet Dictionary with methods as synsets, definitions,examples, antonyms"
      ],
      "metadata": {
        "id": "Tx15oJ2D4Rx-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duZOtbz83fqF",
        "outputId": "230131d1-0666-42d3-c935-e3d64a351cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Word:** phone\n",
            "  * Synsets:\n",
            "      - Word: telephone\n",
            "        - Definition: electronic equipment that converts sound into electrical signals that can be transmitted over distances and then converts received signals back into sounds\n",
            "          - Examples: ['I talked to him on the telephone']\n",
            "      - Word: phone\n",
            "        - Definition: (phonetics) an individual sound unit of speech without concern as to whether or not it is a phoneme of some language\n",
            "          - Examples: []\n",
            "      - Word: earphone\n",
            "        - Definition: electro-acoustic transducer for converting electric signals into sounds; it is held over or inserted into the ear\n",
            "          - Examples: ['it was not the typing but the earphones that she disliked']\n",
            "      - Word: call\n",
            "        - Definition: get or try to get into communication (with someone) by telephone\n",
            "          - Examples: ['I tried to call you all night', 'Take two aspirin and call me in the morning']\n",
            "----------------------------------------\n",
            "\n",
            "**Antonyms for 'buy':\n",
            "  - sell\n"
          ]
        }
      ],
      "source": [
        "# NLP 3A. Study of Wordnet Dictionary with methods as synsets, definitions, examples, antonyms\n",
        "# Import necessary libraries\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Download WordNet (if not already downloaded)\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Get synsets (collection of synonyms) for \"phone\"\n",
        "synsets = wordnet.synsets(\"phone\")\n",
        "\n",
        "# Print information about \"phone\"\n",
        "print(\"**Word:** phone\")\n",
        "print(\"  * Synsets:\")\n",
        "\n",
        "# Loop through each synset and print its definition and examples\n",
        "for synset in synsets:\n",
        "    # Get the first word from the synset (considered the most representative)\n",
        "    word = synset.lemmas()[0].name()\n",
        "    print(f\"      - Word: {word}\")\n",
        "    print(f\"        - Definition: {synset.definition()}\")\n",
        "    print(f\"          - Examples: {synset.examples()}\")\n",
        "\n",
        "\n",
        "print(\"-\"*40)\n",
        "# Get antonyms for \"buy\" (verb)\n",
        "antonyms = wordnet.lemma('buy.v.01.buy').antonyms()\n",
        "\n",
        "# Print antonyms for \"buy\"\n",
        "print(\"\\n**Antonyms for 'buy':\")\n",
        "for antonym in antonyms:\n",
        "    print(f\"  - {antonym.name()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# NLP 3B Study lemmas, hyponyms, hypernyms."
      ],
      "metadata": {
        "id": "en8DDQUT4T61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLP 3B Study lemmas, hyponyms, hypernyms.\n",
        "\n",
        "# Import necessary libraries\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Download WordNet (if not already downloaded)\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Exploring Lemmas\n",
        "print(\"\\n**Lemmas**\")\n",
        "synsets = wordnet.synsets(\"computer\")\n",
        "print(\"  * Synsets and Lemmas:\")\n",
        "for synset in synsets:\n",
        "    lemma_names = [lemma.name() for lemma in synset.lemmas()]\n",
        "    print(f\"      - Synset: {synset} --> Lemmas: {lemma_names}\")\n",
        "\n",
        "# Exploring Hyponyms\n",
        "print(\"\\n**Hyponyms**\")\n",
        "computer_synset = wordnet.synset(\"computer.n.01\")\n",
        "hyponyms = computer_synset.hyponyms()\n",
        "print(\"  * Hyponyms of 'computer.n.01':\")\n",
        "for synset in hyponyms:\n",
        "    lemma_names = [lemma.name() for lemma in synset.lemmas()]\n",
        "    print(f\"      - Synset: {synset} --> Lemmas: {lemma_names}\")\n",
        "\n",
        "# Exploring Hypernyms\n",
        "print(\"\\n**Hypernyms**\")\n",
        "vehicle_synset = wordnet.synset(\"vehicle.n.01\")\n",
        "car_synset = wordnet.synset(\"car.n.01\")\n",
        "lowest_common_hypernym = car_synset.lowest_common_hypernyms(vehicle_synset)\n",
        "print(f\"  * Lowest common hypernym of 'vehicle' and 'car': {lowest_common_hypernym[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybh1a0CV4U2-",
        "outputId": "574ae33d-ddd4-4789-fad8-22674ada8f8b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**Lemmas**\n",
            "  * Synsets and Lemmas:\n",
            "      - Synset: Synset('computer.n.01') --> Lemmas: ['computer', 'computing_machine', 'computing_device', 'data_processor', 'electronic_computer', 'information_processing_system']\n",
            "      - Synset: Synset('calculator.n.01') --> Lemmas: ['calculator', 'reckoner', 'figurer', 'estimator', 'computer']\n",
            "\n",
            "**Hyponyms**\n",
            "  * Hyponyms of 'computer.n.01':\n",
            "      - Synset: Synset('analog_computer.n.01') --> Lemmas: ['analog_computer', 'analogue_computer']\n",
            "      - Synset: Synset('digital_computer.n.01') --> Lemmas: ['digital_computer']\n",
            "      - Synset: Synset('home_computer.n.01') --> Lemmas: ['home_computer']\n",
            "      - Synset: Synset('node.n.08') --> Lemmas: ['node', 'client', 'guest']\n",
            "      - Synset: Synset('number_cruncher.n.02') --> Lemmas: ['number_cruncher']\n",
            "      - Synset: Synset('pari-mutuel_machine.n.01') --> Lemmas: ['pari-mutuel_machine', 'totalizer', 'totaliser', 'totalizator', 'totalisator']\n",
            "      - Synset: Synset('predictor.n.03') --> Lemmas: ['predictor']\n",
            "      - Synset: Synset('server.n.03') --> Lemmas: ['server', 'host']\n",
            "      - Synset: Synset('turing_machine.n.01') --> Lemmas: ['Turing_machine']\n",
            "      - Synset: Synset('web_site.n.01') --> Lemmas: ['web_site', 'website', 'internet_site', 'site']\n",
            "\n",
            "**Hypernyms**\n",
            "  * Lowest common hypernym of 'vehicle' and 'car': Synset('vehicle.n.01')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# NLP 3C. Write a program using python to find synonym and antonym of word \"active\" using Wordnet."
      ],
      "metadata": {
        "id": "b132V4Au4XRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLP 3C. Write a program using python to find synonym and antonym of word \"active\" using Wordnet.\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "def get_synonyms_antonyms(word):\n",
        "    synonyms = []\n",
        "    antonyms = []\n",
        "\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms.append(lemma.name())\n",
        "            if lemma.antonyms():\n",
        "                antonyms.append(lemma.antonyms()[0].name())\n",
        "\n",
        "    return set(synonyms), set(antonyms)\n",
        "\n",
        "def main():\n",
        "    word = input(\"Enter the word:-\")\n",
        "    synonyms, antonyms = get_synonyms_antonyms(word)\n",
        "\n",
        "    print(\"Synonyms of\", word + \":\", synonyms)\n",
        "    print(\"Antonyms of\", word + \":\", antonyms)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    nltk.download('wordnet')\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb1yA7H94YE-",
        "outputId": "2f98c7a2-bdd7-49d4-db0e-90712775e794"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the word:-active\n",
            "Synonyms of active: {'fighting', 'active', 'dynamic', 'participating', 'alive', 'combat-ready', 'active_agent', 'active_voice'}\n",
            "Antonyms of active: {'passive', 'quiet', 'stative', 'dormant', 'extinct', 'passive_voice', 'inactive'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# NLP 3d. Write a program using python to find synonym and antonym of word \"active\" using Wordnet."
      ],
      "metadata": {
        "id": "5OtopxLB4aMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#d. Write a program using python to find synonym and antonym of word \"active\" using Wordnet.\n",
        "\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "def compare_nouns(noun1, noun2):\n",
        "    # Get synsets for each noun\n",
        "    synsets1 = wn.synsets(noun1, pos=wn.NOUN)\n",
        "    synsets2 = wn.synsets(noun2, pos=wn.NOUN)\n",
        "\n",
        "    if not synsets1 or not synsets2:\n",
        "        return \"Unable to compare. Make sure both nouns are valid.\"\n",
        "\n",
        "    max_wup_similarity = 0\n",
        "    max_path_similarity = 0\n",
        "\n",
        "    for synset1 in synsets1:\n",
        "        for synset2 in synsets2:\n",
        "            # Calculate Wu-Palmer Similarity\n",
        "            wup_similarity = synset1.wup_similarity(synset2)\n",
        "            if wup_similarity is not None and wup_similarity > max_wup_similarity:\n",
        "                max_wup_similarity = wup_similarity\n",
        "\n",
        "            # Calculate Path Similarity\n",
        "            path_similarity = synset1.path_similarity(synset2)\n",
        "            if path_similarity is not None and path_similarity > max_path_similarity:\n",
        "                max_path_similarity = path_similarity\n",
        "\n",
        "    return max_wup_similarity, max_path_similarity\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    noun1 = input(\"Enter the first noun: \")\n",
        "    noun2 = input(\"Enter the second noun: \")\n",
        "\n",
        "    wup_similarity_score, path_similarity_score = compare_nouns(noun1, noun2)\n",
        "\n",
        "    print(f\"The Wu-Palmer Similarity between '{noun1}' and '{noun2}' is: {wup_similarity_score}\")\n",
        "    print(f\"The Path Similarity between '{noun1}' and '{noun2}' is: {path_similarity_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEzyRE0z4bSt",
        "outputId": "b6dfec12-b5bd-475e-9884-7ff8b0cae3cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the first noun: fox\n",
            "Enter the second noun: wolf\n",
            "The Wu-Palmer Similarity between 'fox' and 'wolf' is: 0.9285714285714286\n",
            "The Path Similarity between 'fox' and 'wolf' is: 0.3333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# NLP 3E_a: Using nltk, add or remove stop words in NLTK's Default stop word list\n"
      ],
      "metadata": {
        "id": "f6wZbB2q4dDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLP 3E_a: Using nltk, add or remove stop words in NLTK's Default stop word list\n",
        "# Import necessary libraries\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download stopwords (if not already downloaded)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "print(\"-\"*40)\n",
        "\n",
        "# Sample text\n",
        "text = \"Ninad likes to play Chess, however he is not too good with the football.\"\n",
        "print(\"Given Text:- \",text)\n",
        "# Remove stop words from text\n",
        "text_tokens = word_tokenize(text)\n",
        "stop_words = stopwords.words('english')\n",
        "tokens_without_sw = [word for word in text_tokens if word not in stop_words]\n",
        "print(\"Tokens without stop words:\", tokens_without_sw)\n",
        "\n",
        "# Add custom stop word ('not')\n",
        "custom_stop_words = stop_words + ['not']\n",
        "tokens_without_sw = [word for word in text_tokens if word not in custom_stop_words]\n",
        "print(\"\\nTokens without 'not' (custom stop word):\", tokens_without_sw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Zv4I3PR4eY-",
        "outputId": "9a8f5a21-fe70-4dd6-dd26-eb09668d3775"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "Given Text:-  Ninad likes to play Chess, however he is not too good with the football.\n",
            "Tokens without stop words: ['Ninad', 'likes', 'play', 'Chess', ',', 'however', 'good', 'football', '.']\n",
            "\n",
            "Tokens without 'not' (custom stop word): ['Ninad', 'likes', 'play', 'Chess', ',', 'however', 'good', 'football', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# NLP 3E_b: Using Gensim, add or remove stop words in Default Gensim stop words List.\n"
      ],
      "metadata": {
        "id": "zCAuK_FW4gdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLP 3E_b: Using Gensim, add or remove stop words in Default Gensim stop words List.\n",
        "\n",
        "#pip install scipy==1.12\n",
        "\n",
        "import gensim\n",
        "from gensim.parsing.preprocessing import remove_stopwords, STOPWORDS\n",
        "\n",
        "text = \"Ninad likes to play Chess, however he is not too good with the football.\"\n",
        "\n",
        "# Removing Stop Words\n",
        "filtered_sentence = remove_stopwords(text)\n",
        "print(\"-\"*30)\n",
        "print(\"Original sentence:\", text)\n",
        "print(\"-\"*30)\n",
        "print(\"Stop words removed:\", filtered_sentence)\n",
        "print(\"-\"*30)\n",
        "\n",
        "# Adding Stop Words\n",
        "all_stopwords = STOPWORDS.union(set(['likes', 'play']))\n",
        "text_tokens = text.split()\n",
        "tokens_without_sw = [word for word in text_tokens if word not in all_stopwords]\n",
        "print(\"Original sentence (tokens):\", text_tokens)\n",
        "print(\"-\"*30)\n",
        "print(\"Stop words 'likes' and 'play' added:\", tokens_without_sw)\n",
        "print(\"-\"*30)\n",
        "\n",
        "# Removing Specific Stop Word\n",
        "all_stopwords = STOPWORDS.difference({\"not\"})\n",
        "tokens_without_sw = [word for word in text.split() if word not in all_stopwords]\n",
        "print(\"Original sentence (tokens):\", text.split())\n",
        "print(\"-\"*30)\n",
        "print(\"Stop word 'not' removed:\", tokens_without_sw)\n",
        "print(\"-\"*30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzr3pKQf4iZv",
        "outputId": "7c6405df-6a97-4887-f773-94bddbfc23eb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\n",
            "Original sentence: Ninad likes to play Chess, however he is not too good with the football.\n",
            "------------------------------\n",
            "Stop words removed: Ninad likes play Chess, good football.\n",
            "------------------------------\n",
            "Original sentence (tokens): ['Ninad', 'likes', 'to', 'play', 'Chess,', 'however', 'he', 'is', 'not', 'too', 'good', 'with', 'the', 'football.']\n",
            "------------------------------\n",
            "Stop words 'likes' and 'play' added: ['Ninad', 'Chess,', 'good', 'football.']\n",
            "------------------------------\n",
            "Original sentence (tokens): ['Ninad', 'likes', 'to', 'play', 'Chess,', 'however', 'he', 'is', 'not', 'too', 'good', 'with', 'the', 'football.']\n",
            "------------------------------\n",
            "Stop word 'not' removed: ['Ninad', 'likes', 'play', 'Chess,', 'not', 'good', 'football.']\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# NLP 3E_c: Using SpaCy, add or remove Stop Words in Default SpaCy stop words List."
      ],
      "metadata": {
        "id": "OpQDbaRR4j5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLP 3E_c: Using SpaCy, add or remove Stop Words in Default SpaCy stop words List.\n",
        "\n",
        "#python -m spacy download en_core_web_sm\n",
        "\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "print(\"NLP 3E 3 Using Spacy Adding and Removing Stop Words in Default Spacy Stop Words List\")\n",
        "# Load spaCy model (assuming en_core_web_sm is already downloaded)\n",
        "sp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Get default stop words from spaCy\n",
        "all_stopwords = sp.Defaults.stop_words\n",
        "\n",
        "# Adding Stop Words\n",
        "\n",
        "text = \"Ninad likes to play Chess, however he is not too good with the football.\"\n",
        "text_tokens = word_tokenize(text)\n",
        "\n",
        "# Add \"play\" to stop words\n",
        "all_stopwords.add(\"play\")\n",
        "tokens_without_sw = [word for word in text_tokens if word not in all_stopwords]\n",
        "print(\"Original sentence (tokens):\", text_tokens)\n",
        "print(\"Stop word 'play' added:\", tokens_without_sw)\n",
        "\n",
        "# Removing Specific Stop Word\n",
        "\n",
        "# Remove \"not\" from stop words (modify with caution)\n",
        "all_stopwords.remove(\"not\")\n",
        "tokens_without_sw = [word for word in text_tokens if word not in all_stopwords]\n",
        "print(\"Original sentence (tokens):\", text_tokens)\n",
        "print(\"Stop word 'not' removed:\", tokens_without_sw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_P-NHn64m_N",
        "outputId": "4563320e-957f-4a6c-849f-0471c99a352f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP 3E 3 Using Spacy Adding and Removing Stop Words in Default Spacy Stop Words List\n",
            "Original sentence (tokens): ['Ninad', 'likes', 'to', 'play', 'Chess', ',', 'however', 'he', 'is', 'not', 'too', 'good', 'with', 'the', 'football', '.']\n",
            "Stop word 'play' added: ['Ninad', 'likes', 'Chess', ',', 'good', 'football', '.']\n",
            "Original sentence (tokens): ['Ninad', 'likes', 'to', 'play', 'Chess', ',', 'however', 'he', 'is', 'not', 'too', 'good', 'with', 'the', 'football', '.']\n",
            "Stop word 'not' removed: ['Ninad', 'likes', 'Chess', ',', 'not', 'good', 'football', '.']\n"
          ]
        }
      ]
    }
  ]
}