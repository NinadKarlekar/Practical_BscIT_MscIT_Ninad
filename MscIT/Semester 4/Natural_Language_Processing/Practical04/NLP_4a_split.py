# 4A. Tokenization using Python’s split() function

# Sample text to tokenize
text = "Hello ! My name is Ninad Karlekar I live in mumbai"

# Tokenizing the text using split()
tokens = text.split()

# Printing the tokens
print("="*60)
print("4A. Tokenization using Python’s split() function")
print("-"*10)
print("Tokens:", tokens)
print("="*60)